{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ASR-CL\n",
    "## Lucida AI Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal\n",
    "Investigate the relationship between the errors of ASR (Automatic Speech Recognition) and the errors of CL (Classifier for query)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate Quries from Original Data\n",
    "\n",
    "100 sentences on QA (Generic QA; from a public dataset) and 100 sentences on CA (Calendar; hand-made)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aac1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string, sys, json\n",
    "from random import randrange\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"font\", size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What party had a victory in the 2015 UK election?,QA\n",
      "What is the main difference between online pharmacies and community pharmacies?,QA\n",
      "What type of treatment are pharmacists important for?,QA\n",
      "Who did Genghis Khan unite before he began conquering the rest of Eurasia?,QA\n",
      "In what year was HMS Dreadnought launched?,QA\n",
      "What cytokines are responsible for communication between white blood cells?,QA\n",
      "What are some proposals to connect campuses?,QA\n",
      "What compounds can be masked with the molecules of the host cell in order for a virus to evade detection?,QA\n",
      "Where did the residents of Antioch flee to?,QA\n",
      "Who designed the garden for the University Library?,QA\n",
      "The adaptive immune system must distinguish between what types of molecules?,QA\n",
      "ABC had secondary status on the existing stations in what Ohio town?,QA\n",
      "Why would one plead guilty to a crime involving civil disobedience?,QA\n",
      "What is the role of teachers in education?,QA\n",
      "Who claimed that the name Black Death first appeared in 1631?,QA\n",
      "What is the nickname for the Delta in the Netherlands?,QA\n",
      "Western governments considered Islamists to be the lesser of two evils when compared to whom?,QA\n",
      "How many tonnes of tomatoes does Victoria produce?,QA\n",
      "In what complexity class do complement problems of NP problems exist?,QA\n",
      "What charter has become an important aspect of EU law?,QA\n",
      "How has civil disobedience evolved in current times?,QA\n",
      "Whose relics reside in the Becket Casket?,QA\n",
      "Where was a cinema relocated while repairs were underway?,QA\n",
      "During what period did downtown Fresno thrive?,QA\n",
      "Who sets the work agenda and allocates time in the chamber?,QA\n",
      "Who had no real military power during the Yuan?,QA\n",
      "How many types of movements do euplokamis tentilla have?,QA\n",
      "Some in the UMC feel that false ecumenism might result in what?,QA\n",
      "What is the major tributary of the Rhine?,QA\n",
      "How many metric tons of carbon are believed to be stored in the Amazon forest?,QA\n",
      "Why do some people chose to go to jail for their disobedience?,QA\n",
      "How many valves did the Corliss engine use?,QA\n",
      "What was the bubonic plague mechanism reliant on?,QA\n",
      "To what can the use of prolonged breathing of oxygen at 60 kPa lead?,QA\n",
      "When was the British Nationality Act passed?,QA\n",
      "By which year did the American cars mpg start to improve?,QA\n",
      "What was the name of the upgraded Saturn I called?,QA\n",
      "What period did the Rhine capture streams?,QA\n",
      "How many did this epidemic in China kill?,QA\n",
      "What is usually the goal of taking a plea bargain?,QA\n",
      "Who is seen as the ultimate climate change authority?,QA\n",
      "The owner typically awards a contract to who?,QA\n",
      "Between 1978 an d2008 four year full time undergraduate students were required to complete how many classes outside of their concentration?,QA\n",
      "Who was drawn to Jacksonville in the 1910s?,QA\n",
      "In which year did the newspaper define southern California?,QA\n",
      "How long has Proportionality been recognized as one of the general principles of EU law?,QA\n",
      "What have some plants repurposed the peptidoglycan layer genes for?,QA\n",
      "Which region began to grow and assert itself in the 2000s?,QA\n",
      "What year did the the case go before the supreme court?,QA\n",
      "What park is close to John Lennon street?,QA\n",
      "When was Dali conquered by the Yuan?,QA\n",
      "How many Nobel Laureates are among the school alumni?,QA\n",
      "When is the last time a fumble return touchdown happened in a Super Bowl?,QA\n",
      "What generally does not allow citizens to sue other citizens?,QA\n",
      "How many days did the Warsaw Uprising last?,QA\n",
      "Under what condition is an element irreducible?,QA\n",
      "What are two complexity classes between L and P?,QA\n",
      "Who did Tesla credit for his abilities?,QA\n",
      "What does a teacher teach in primary school?,QA\n",
      "What type of value would the zeta function have if there were finite primes?,QA\n",
      "Gosforth and Byker are the largest shopping areas of what type?,QA\n",
      "What had to happen to each mission before they would continue on to the next mission?,QA\n",
      "What is the process of vaccination also known as?,QA\n",
      "What did Gasquet think the plague was?,QA\n",
      "By how much did Labour lead Lain Gray retain East Lothian?,QA\n",
      "How many households has kids under the age of 18 living in them?,QA\n",
      "What alumni is also the Governor of the Bank of Japan?,QA\n",
      "Which material is the Gloucester Candlestick made from?,QA\n",
      "What did the use of steam engines in farming lead to?,QA\n",
      "In what year did Fresno get its first pedestrian mall?,QA\n",
      "Who did BSkyB team up with because it was not part of the consortium?,QA\n",
      "What is the eukaryotic parasite responsible for malaria known as?,QA\n",
      "What was carried on extended lunar missions?,QA\n",
      "When did Luther waken with more chest pains?,QA\n",
      "How were enemy prisoners used tactically by Mongol armies?,QA\n",
      "What armed group stopped the uprising at Ballarat?,QA\n",
      "What is the main judicial body of the EU?,QA\n",
      "What gets transferred to students who are receptive to the teacher?,QA\n",
      "How many members in the seats of the Scottish Parliament are members of the Scottish Government?,QA\n",
      "When is the suspended team scheduled to return?,QA\n",
      "What is the lake known as which was created by the rise of the Andes Mountains?,QA\n",
      "What platform was Sentanta Sports planning on launching on?,QA\n",
      "How long will the event at Santa Clara Convention Center last?,QA\n",
      "Which gender is more populous across all groups in Jacksonville?,QA\n",
      "What weapon does Spike Milligan use against a Dalek?,QA\n",
      "What councils assign tasks to the IPCC?,QA\n",
      "At what time did Tesla get dinner?,QA\n",
      "What reasons cause failure of the disobedience with authorities?,QA\n",
      "In what group of compounds is oxygen a necessary part?,QA\n",
      "What was a Happy Days spinoff that debuted in the 1980s on ABC?,QA\n",
      "What percentage of Filipino primary school students are in private schools?,QA\n",
      "What court case desegregated schools in the United States?,QA\n",
      "what do conquering people pass down to native populations?,QA\n",
      "When did the Siege of Antioch take place?,QA\n",
      "How many BSkyB channels were available to customers prior to October 2005?,QA\n",
      "What brought the downfall of Jacksonville filmmaking?,QA\n",
      "What is the gender income inequality in Bahrain?,QA\n",
      "What techniques can be used to determine paleotopography?,QA\n",
      "What type of organization would need large quantities of pure oxygen?,QA\n",
      "In what year did the Amazon experience a drought that may have been more extreme than in 2005?,QA\n",
      "What is on the Google calendar?,CA\n",
      "What does my Google calendar tell me to do?,CA\n",
      "What does the calendar say that I ought to do?,CA\n",
      "What did Google say I should do tomorrow?,CA\n",
      "What does the Google calendar thing say?,CA\n",
      "What am I going to do?,CA\n",
      "What is my plan?,CA\n",
      "What are on my plan during the next week?,CA\n",
      "What plan do I have for next month?,CA\n",
      "What stuff have been put on my plan?,CA\n",
      "What plan have I made?,CA\n",
      "What plan has been made?,CA\n",
      "What kind of stuff am I supposed to this afternoon?,CA\n",
      "What kind of thing to do?,CA\n",
      "What to do next week?,CA\n",
      "What has shown up on schedule?,CA\n",
      "Does the schedule say I am going to work?,CA\n",
      "Does the schedule force me to do anything?,CA\n",
      "Do I need to work today?,CA\n",
      "Do I need to spend 2 hours fixing computers tomorrow?,CA\n",
      "Do I have to do something today?,CA\n",
      "Do I have to read the book tonight?,CA\n",
      "Do I make any appointment recently?,CA\n",
      "What appointment have I arranged?,CA\n",
      "What appointment shows up in the schedule?,CA\n",
      "Is there any chunk of my time reserved today?,CA\n",
      "Am I totally booked today?,CA\n",
      "Am I free Wednesday noon?,CA\n",
      "Will I be available to do something tomorrow afternoon?,CA\n",
      "When should I start doing the stuff on my schedule?,CA\n",
      "What is the schedule?,CA\n",
      "What is on my schedule?,CA\n",
      "What schedule do I have?,CA\n",
      "What schedule did I make?,CA\n",
      "What did I do last week?,CA\n",
      "What have I done last year?,CA\n",
      "What have I been doing since last Tuesday?,CA\n",
      "What did I do last Thanksgiving? ,CA\n",
      "What does the calendar tell about my last week’s schedule?,CA\n",
      "What do you know about my plan?,CA\n",
      "When did I go shopping last week?,CA\n",
      "What did I do after watching the movie yesterday?,CA\n",
      "Am I going to do anything today?,CA\n",
      "Am I going to attend a meeting at 10?,CA\n",
      "What is my entire calendar for 2015?,CA\n",
      "What is my schedule for 2017?,CA\n",
      "What should I do for the next couple of days?,CA\n",
      "What am I going to do tomorrow morning?,CA\n",
      "What will I do for the following week?,CA\n",
      "What will I do for the next couple of hours?,CA\n",
      "What is on my plate today?,CA\n",
      "What was on my plate last night?,CA\n",
      "What will be on my plate this Saturday afternoon?,CA\n",
      "What is the earliest class I have for tomorrow?,CA\n",
      "When will the lecture finish tomorrow afternoon?,CA\n",
      "What do I do after class everyday?,CA\n",
      "What am I doing before dinner at 6 pm?,CA\n",
      "What activity do I usually do in the morning?,CA\n",
      "What activity will I do tomorrow morning?,CA\n",
      "Did I spent several hours reading books last month?,CA\n",
      "How often did I travel last year?,CA\n",
      "How long did travelling cost me last week?,CA\n",
      "How long will I spend on programming next week?,CA\n",
      "How long will the final exam be in December?,CA\n",
      "\"What exactly did I do on November 22, 2016?\",CA\n",
      "List my events tomorrow.,CA\n",
      "List my schedule.,CA\n",
      "Tell me if I am free from 5 to 7 tonight.,CA\n",
      "Could you tell me my plan today?,CA\n",
      "Do you mind reporting my calendar for this week? ,CA\n",
      "Please give the events on the schedule. ,CA\n",
      "Please tell me the stuff I am supposed to do right now.,CA\n",
      "Please say yes if I am busy all day today.,CA\n",
      "Return no if I won’t be free tomorrow.,CA\n",
      "Is it okay for me to spend 3 hours playing football tonight?,CA\n",
      "Am I fine if I cook tomorrow night for 30 minutes?,CA\n",
      "Am I a busy person in 2016 in the United States?,CA\n",
      "What have I been doing since I came to the United States in 2014?,CA\n",
      "How often have I been to that restaurant since last week?,CA\n",
      "How often will I go to the park given my current daily routine?,CA\n",
      "Do you predict that I will be free at 5 today?,CA\n",
      "How much time did I spend in the United States last year?,CA\n",
      "How much time should I spend sleeping everyday?,CA\n",
      "How much free time do I have today?,CA\n",
      "How long will it be from when I am done all the work to midnight?,CA\n",
      "Is tomorrow 8 am a good time for me to attend a meeting in the EECS building?,CA\n",
      "What is my frequency of listening to music since last Monday?,CA\n",
      "How long has it been since my last shopping?,CA\n",
      "How long has passed since the last time the house was cleaned up according to my plan?,CA\n",
      "\"According to the schedule, will I be able to watch TV tomorrow night?\",CA\n",
      "Is there any way 2 hours can be arranged?,CA\n",
      "What am I doing right now from the calendar?,CA\n",
      "Who am I going to meet tonight?,CA\n",
      "Who am I going to study with next month?,CA\n",
      "Who am I going to spend the next few hours with?,CA\n",
      "Who has spent 2 hours with me last night?,CA\n",
      "Who has spent some time with me since I went to this university in 2014?,CA\n",
      "Who should I spend time with according to my habit inferred?,CA\n",
      "Who is the person I have spent most time with last year?,CA\n",
      "Who is going to talk with me?,CA\n"
     ]
    }
   ],
   "source": [
    "# Return true if the string contains any of the characters in the set.\n",
    "def contains_any(str, set):\n",
    "    return 1 in [c in str for c in set]\n",
    "\n",
    "# Generate 100 queires from the original data file\n",
    "# 'dev-v1.1.json'.\n",
    "# Format: JSON.\n",
    "# Print out the queries.\n",
    "# Data source: https://rajpurkar.github.io/SQuAD-explorer/.\n",
    "def generate_100_queires():\n",
    "    with open('dev-v1.1.json') as json_data:\n",
    "        d = json.load(json_data)\n",
    "    count = 0\n",
    "    while True:\n",
    "        seen = {}\n",
    "        if count >= 100:\n",
    "            break\n",
    "        data = d['data'][randrange(len(d['data']))]\n",
    "        paragraph = data['paragraphs'][randrange(len(data['paragraphs']))]\n",
    "        qa = paragraph['qas'][randrange(len(paragraph['qas']))]\n",
    "        query = qa['question']\n",
    "        if query in seen or contains_any(query[:-1], string.punctuation) \\\n",
    "        or not '?' in query or len(query.split()) < 7 or '  ' in query:\n",
    "            continue\n",
    "        seen[query] = 1\n",
    "        print(query)\n",
    "        count += 1\n",
    "\n",
    "# Label the first `first_part` queries as `QA`, and the rest as `CA`.\n",
    "# Print the label transcripts.\n",
    "def label_transcript(transcript_file_path, first_part):\n",
    "    file = open(transcript_file_path)\n",
    "    lines= file.readlines()\n",
    "    file.close()\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.rstrip('\\n')\n",
    "        if ',' in line:\n",
    "            line = '\"' + line + '\"'\n",
    "        print(line + ',' + ('QA' if i < first_part else 'CA'))\n",
    "    \n",
    "# generate_100_queires() # save the result to 'speech/transcript.txt'\n",
    "label_transcript('speech/transcript.txt', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate Raw Data by Sending Queries to the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate DataFrame from ASR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 166, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f5de27d3e1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text/query.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# asr_labels = ['fisher', 'librispeech', 'tedlium']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:8748)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:9003)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:9731)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:9602)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:23325)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 166, saw 3\n"
     ]
    }
   ],
   "source": [
    "# Return a DataFrame from the file with the following format:\n",
    "# <audio_path>,<transcript>\n",
    "# in which the audio path is of the following format:\n",
    "# \"path/to/file/<query_id>_<text>.wav\"\n",
    "# An example file:\n",
    "# ../asr_mt/speech/0_Helloworld.wav,\"hello world.\"\n",
    "# Its first line must have be the header!\n",
    "# The DataFrame has only one column: transcript\n",
    "# with the specified header\n",
    "# and sorted by the query id.\n",
    "def get_df_from_asr_result(file_path, header):\n",
    "    file = open(file_path, 'r')\n",
    "    lines = file.readlines()\n",
    "    lines.pop(0) # pop the header\n",
    "    file.close()\n",
    "    proc_lines = []\n",
    "    for line in lines:\n",
    "        line = line.lstrip().rstrip('\\n')\n",
    "        # The first occurrence of a number is assumed to be the query id.\n",
    "        id = int(re.search(r'\\d+', line).group())\n",
    "        transcript = line.split(',')[1]\n",
    "        if transcript.startswith('\"') and transcript.endswith('\"'):\n",
    "            transcript = transcript[1:-1]\n",
    "        proc_lines.append((id, transcript))\n",
    "    proc_lines.sort(key=itemgetter(0)) # sort data by ID\n",
    "    df = pd.DataFrame([row[1] for row in proc_lines], columns=[header])\n",
    "    return df\n",
    "\n",
    "data = pd.read_csv('text/query.txt')\n",
    "\n",
    "# asr_labels = ['fisher', 'librispeech', 'tedlium']\n",
    "\n",
    "# for asr_label in asr_labels:\n",
    "#     data = data.join \\\n",
    "#     (get_df_from_asr_result('asr_result_{}.txt'.format(asr_label), \\\n",
    "#                             'transcript_{}'.format(asr_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "oldstdout = sys.stdout\n",
    "# sys.stdout = open('log.txt', 'w')\n",
    "# Return a DataFrame from Google MT result data\n",
    "# and evaluate the result using the BLEU metric.\n",
    "# In order to match the query in the Google MT result data\n",
    "# to the query in `data`,\n",
    "# the column name to match should be specified.\n",
    "def get_df_from_google_result(mt_label, data, match_col):\n",
    "    sys.path.append('../../mt')\n",
    "    from bleu import Evaluator\n",
    "    e = Evaluator()\n",
    "    google_data = pd.read_csv('mt_result_{}.txt'.format(mt_label))\n",
    "    results = []\n",
    "    for j, asr_output in enumerate(data[match_col]):\n",
    "        print(mt_label, asr_output)\n",
    "        print(data['query'].ix[j])\n",
    "        match_row = -1\n",
    "        if asr_output != '':\n",
    "            for i, mt_input in enumerate(google_data['text']):\n",
    "                # Some weird problem leads to some '\"' left in the sentence.\n",
    "                mt_input = mt_input.replace('\"', '')\n",
    "                if mt_input == asr_output.replace('\"', ''):\n",
    "                    match_row = i\n",
    "                    break\n",
    "            if match_row == -1:\n",
    "                raise RuntimeError('Cannot find the query ' + asr_output)\n",
    "            result = google_data['translation'].ix[match_row]\n",
    "        else:\n",
    "            result = None # ASR did not return any result, so MT must be wrong!\n",
    "        score = e.evaluate(result, data['answer'].ix[j])\n",
    "        results.append((j, result, score))\n",
    "        sys.stdout.flush()\n",
    "    assert(len(results) == data.shape[0])\n",
    "    results.sort(key=itemgetter(0)) # sort data by row index\n",
    "    df = pd.DataFrame({'answer_{}'.format(mt_label): [row[1] for row in results], \\\n",
    "                      'score_{}'.format(mt_label): [row[2] for row in results]})\n",
    "    return df\n",
    "    \n",
    "# mt_labels = [('fisher_google', 'transcript_fisher'), \\\n",
    "#              ('fisher_microsoft', 'transcript_fisher'), \\\n",
    "#              ('librispeech_google', 'transcript_librispeech'), \\\n",
    "#              ('librispeech_microsoft', 'transcript_librispeech'), \\\n",
    "#              ('tedlium_google', 'transcript_tedlium'), \\\n",
    "#              ('tedlium_microsoft', 'transcript_tedlium'), \\\n",
    "#              ('regular_google', 'query'), \\\n",
    "#              ('regular_microsoft', 'query')]\n",
    "\n",
    "# for mt_label, match_col in mt_labels:\n",
    "#     data = data.join \\\n",
    "#     (get_df_from_google_result(mt_label, data, match_col), lsuffix='')\n",
    "# data = data[['query', 'answer', \n",
    "#              'answer_regular_google', 'score_regular_google', \\\n",
    "#              'answer_regular_microsoft', 'score_regular_microsoft', \\\n",
    "#              'transcript_fisher', \\\n",
    "#              'answer_fisher_google', 'score_fisher_google', \\\n",
    "#              'answer_fisher_microsoft', 'score_fisher_microsoft', \\\n",
    "#              'transcript_librispeech', \\\n",
    "#              'answer_librispeech_google', 'score_librispeech_google', \\\n",
    "#              'answer_librispeech_microsoft', 'score_librispeech_microsoft', \\\n",
    "#              'transcript_tedlium', \\\n",
    "#              'answer_tedlium_google', 'score_tedlium_google', \\\n",
    "#              'answer_tedlium_microsoft', 'score_tedlium_microsoft']]\n",
    "# data.to_csv('data.txt') # save to disk\n",
    "sys.stdout = oldstdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'data.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c1b5c4ea6c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# display full text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# display all columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yba/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'data.txt' does not exist"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', -1) # display full text\n",
    "data = pd.read_csv('data.txt', index_col=0)\n",
    "pd.set_option('display.max_columns', data.shape[1]) # display all columns\n",
    "data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Statistics and Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot Google MT Performance\n",
    "\n",
    "1. Baseline is Google MT with the original text query\n",
    "\n",
    "2. Score is relative to the baseline:\n",
    "\n",
    "    - If the baseline is more correct, the score is -1\n",
    "\n",
    "    - If the baseline is more wrong, the score is +1\n",
    "\n",
    "    - Otherwise, the score is 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../asr')\n",
    "from wer import error_rate\n",
    "\n",
    "# Analyze the data for the specified ASR and return the statistics.\n",
    "def analyze(data, asr_name, mt_name):\n",
    "    size = data.shape[0]\n",
    "    asr_errors = np.zeros(size)\n",
    "    for j, transcript in enumerate(data['_'.join(['transcript', asr_name])]):\n",
    "        asr_errors[j] = error_rate(data['query'][j], transcript)\n",
    "    relative_scores = np.zeros(size)\n",
    "    with_asr_scores = data['_'.join(['score', asr_name, mt_name])]\n",
    "    regular_scores = data['_'.join(['score', 'regular', mt_name])]\n",
    "    for j, answer in enumerate(data['_'.join(['answer', asr_name, mt_name])]):\n",
    "        with_asr_score = with_asr_scores[j]\n",
    "        regular_score = regular_scores[j]\n",
    "        if with_asr_score == regular_score:\n",
    "            relative_scores[j] = 0\n",
    "        elif with_asr_score > regular_score:\n",
    "            relative_scores[j] = -1\n",
    "        else:\n",
    "            relative_scores[j] = 1\n",
    "    avg_mt_accuracy = np.mean(with_asr_scores)\n",
    "    avg_regular_mt_accuracy = np.mean(regular_scores)\n",
    "    print('avg_asr_error:', asr_errors.mean(), \\\n",
    "          'avg_mt_accuracy:', avg_mt_accuracy, \\\n",
    "          'avg_regular_mt_accuracy', avg_regular_mt_accuracy)\n",
    "    return {'asr_name': asr_name, 'mt_name': mt_name, \\\n",
    "            'asr_errors': asr_errors, \\\n",
    "            'avg_asr_error': asr_errors.mean(), \\\n",
    "            'relative_scores': relative_scores, \\\n",
    "            'avg_mt_accuracy': avg_mt_accuracy, \\\n",
    "            'avg_regular_mt_accuracy': avg_regular_mt_accuracy}\n",
    "\n",
    "# Plot the relative scores vs error rates for a particular ASR+MT combination.\n",
    "def plot_score_vs_error(color, asr_name, mt_name, asr_errors, relative_scores, **extras):\n",
    "    plt.xlabel('ASR Error Rate')\n",
    "    plt.ylabel('MT Relative Score')\n",
    "    plt.title(' '.join([asr_name, mt_name]))\n",
    "    plt.scatter(asr_errors, relative_scores, label=asr_name, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "google_stats_list = []\n",
    "google_stats_list.append(analyze(data, 'fisher', 'google'))\n",
    "plot_score_vs_error('lightcoral', **google_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "google_stats_list.append(analyze(data, 'librispeech', 'google'))\n",
    "plot_score_vs_error('lightskyblue', **google_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "google_stats_list.append(analyze(data, 'tedlium', 'google'))\n",
    "plot_score_vs_error('yellowgreen', **google_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Return the data from the list of MT statistics (one for each ASR model).\n",
    "def gather_data_for_mt_vs_asr(stats_list):\n",
    "    asr_name_list = [stats['asr_name'] for stats in stats_list]\n",
    "    avg_asr_accuracy_list = [1 - stats['avg_asr_error'] for stats in stats_list]\n",
    "    avg_mt_accuracy_list = [stats['avg_mt_accuracy'] for stats in stats_list]\n",
    "    avg_regular_mt_accuracy_list = \\\n",
    "    [stats['avg_regular_mt_accuracy'] for stats in stats_list]\n",
    "    avg_mt_accuracy_drop_list = \\\n",
    "    [stats['avg_mt_accuracy'] - avg_regular_mt_accuracy_list[i] \\\n",
    "     for i, stats in enumerate(stats_list)]\n",
    "    avg_mt_accuracy_drop_percentage_list = \\\n",
    "    [ (avg_mt_accuracy_drop / avg_regular_mt_accuracy_list[i]) * 100 \\\n",
    "     for i, avg_mt_accuracy_drop in enumerate(avg_mt_accuracy_drop_list)]\n",
    "    return asr_name_list, avg_asr_accuracy_list, avg_mt_accuracy_list, \\\n",
    "avg_regular_mt_accuracy_list, avg_mt_accuracy_drop_list, \\\n",
    "avg_mt_accuracy_drop_percentage_list\n",
    "\n",
    "# Plot the performance of a particular MT under the influence of different ASR models.\n",
    "def plot_mt_vs_asr(stats_list, mt_name, color):  \n",
    "    assert(len(stats_list) != 0)\n",
    "    plt.xlabel('Average ASR Accuracy')\n",
    "    plt.ylabel('Average MT Accuracy')\n",
    "    plt.title('Performace of {}\\n under the influence of ASR'.format(mt_name))\n",
    "    # Gather data.\n",
    "    asr_name_list, avg_asr_accuracy_list, avg_mt_accuracy_list, \\\n",
    "    avg_regular_mt_accuracy_list, \\\n",
    "    avg_mt_accuracy_drop_list, avg_mt_accuracy_drop_percentage_list = \\\n",
    "    gather_data_for_mt_vs_asr(stats_list)\n",
    "    # Plot.\n",
    "    plt.scatter(avg_asr_accuracy_list, avg_mt_accuracy_list, color=color)\n",
    "    for i, avg_asr_accuracy in enumerate(avg_asr_accuracy_list):\n",
    "        txt = '{} ({:.2f},{:.3f})\\n$\\Delta$Accuracy={:.3f}\\n({:.2f}%)'.format \\\n",
    "        (asr_name_list[i], avg_asr_accuracy, avg_mt_accuracy_list[i], \\\n",
    "         avg_mt_accuracy_drop_list[i], \\\n",
    "         avg_mt_accuracy_drop_percentage_list[i])\n",
    "        plt.annotate(txt, (avg_asr_accuracy, avg_mt_accuracy_list[i]), \\\n",
    "                    fontsize=10)\n",
    "\n",
    "# Plot the performance of a different MTs under the influence of different ASR models.\n",
    "def plot_mts_vs_asr(list_of_stats_list, list_of_mt_name, list_of_colors):\n",
    "    assert(len(list_of_stats_list) != 0)\n",
    "    assert(len(list_of_stats_list[0]) != 0)\n",
    "    assert(len(list_of_stats_list) == len(list_of_mt_name))\n",
    "    assert(len(list_of_mt_name) == len(list_of_colors))\n",
    "    plt.xlabel('Average ASR Accuracy')\n",
    "    plt.ylabel('Average MT Accuracy')\n",
    "    plt.title('Performace of {}\\nunder the influence of ASR'. \\\n",
    "              format(', '.join(list_of_mt_name)))\n",
    "    for i, stats_list in enumerate(list_of_stats_list):\n",
    "        mt_name = list_of_mt_name[i]\n",
    "        # Gather data.\n",
    "        asr_name_list, avg_asr_accuracy_list, avg_mt_accuracy_list, \\\n",
    "        avg_regular_mt_accuracy_list, \\\n",
    "        avg_mt_accuracy_drop_list, avg_mt_accuracy_drop_percentage_list = \\\n",
    "        gather_data_for_mt_vs_asr(stats_list)\n",
    "        # Plot.\n",
    "        plt.scatter(avg_asr_accuracy_list, avg_mt_accuracy_list, \\\n",
    "                    label='{} with ASR'.format(mt_name), \\\n",
    "                    color=list_of_colors[i])\n",
    "        xs = np.arange(0.28, 0.36, 0.02)\n",
    "        plt.plot(xs, \\\n",
    "                 np.full(xs.shape, avg_regular_mt_accuracy_list[0]), \\\n",
    "                 'k--', color=list_of_colors[i], \\\n",
    "                 label='{} Regular'.format(mt_name))\n",
    "        plt.legend(loc='best', fontsize=9)\n",
    "        for i, avg_asr_accuracy in enumerate(avg_asr_accuracy_list):\n",
    "            txt = '{}'.format(asr_name_list[i])\n",
    "            plt.annotate(txt, (avg_asr_accuracy, avg_mt_accuracy_list[i]), \\\n",
    "                         fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_mt_vs_asr(google_stats_list, 'Google MT', 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot Microsoft MT Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "microsoft_stats_list = []\n",
    "microsoft_stats_list.append(analyze(data, 'fisher', 'microsoft'))\n",
    "plot_score_vs_error('lightcoral', **microsoft_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "microsoft_stats_list.append(analyze(data, 'librispeech', 'microsoft'))\n",
    "plot_score_vs_error('lightskyblue', **microsoft_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "microsoft_stats_list.append(analyze(data, 'tedlium', 'microsoft'))\n",
    "plot_score_vs_error('yellowgreen', **microsoft_stats_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_mt_vs_asr(microsoft_stats_list, 'Microsoft MT', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot_mts_vs_asr([google_stats_list, microsoft_stats_list], \\\n",
    "                ['Google MT', 'Microsoft MT'], ['red', 'blue'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
