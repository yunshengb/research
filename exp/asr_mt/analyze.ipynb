{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ASR-MT\n",
    "## Lucida AI Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goal\n",
    "Investigate the relationship between the errors of ASR (Automatic Speech Recognition) and the errors of MT (Machine Translation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Generate Quries from Original Data\n",
    "\n",
    "100 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1047a3470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, string\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.rc(\"font\", family=\"serif\")\n",
    "plt.rc(\"font\", size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return the Ensligh text corresponding to the specific sentence.\n",
    "def get_English_text(id):\n",
    "    links_with_id = links.loc[links['id'] == id]\n",
    "    for translation_id in links_with_id['translation_id']:\n",
    "        data_with_id = data.loc[data['id'] == translation_id]\n",
    "        for index, row in data_with_id.iterrows():\n",
    "            if row['lang'] == 'eng':\n",
    "                return row['text']\n",
    "\n",
    "# Generate 100 queires from the original data files\n",
    "#'sentences.csv' and 'links.csv'.\n",
    "# Format: 'Ensligh text','Chinese text'\n",
    "# Save the queries to 'text/query.txt'.\n",
    "# Data source: http://tatoeba.org/eng/downloads.\n",
    "def generate_100_queires():\n",
    "    data = pd.read_csv('sentences.csv', \\\n",
    "                       names = [\"id\", \"lang\", \"text\"], delimiter='\\t')\n",
    "    chinese_rows = data.loc[data['lang'] == 'cmn']\n",
    "    links = pd.read_csv('links.csv', \\\n",
    "                        names = [\"id\", \"translation_id\"], delimiter='\\t')\n",
    "    num_queries = 100\n",
    "    header = ['query', 'chinese']\n",
    "    query_data = pd.DataFrame(np.zeros((num_queries, len(header))), \\\n",
    "                              columns=header)\n",
    "    # Randomly select 1000 rows, and pick 100 from them as queries.\n",
    "    chinese_rows = chinese_rows.ix[np.random.choice(chinese_rows.index, 1000)]\n",
    "    chinese_rows = chinese_rows.assign(english=np.zeros(chinese_rows.shape[0]))\n",
    "    count = 0\n",
    "    for index, row in chinese_rows.iterrows():\n",
    "        if count >= num_queries:\n",
    "            break\n",
    "        english = get_English_text(row['id'])\n",
    "        # Prefer long sentences without '.', ';', '?', or '!'.\n",
    "        if english is not None and not '.' in english[0:-1] and \\\n",
    "        not ';' in english[0:-1] and not '?' in english[0:-1] and \\\n",
    "        not '!' in english[0:-1] and \\\n",
    "        len(english.split()) >= 10:\n",
    "            query_data.ix[count, 'query'] = english\n",
    "            query_data.ix[count, 'chinese'] = row['text']\n",
    "            count += 1\n",
    "    if count < num_queries:\n",
    "        raise RuntimeError('Too few data!')\n",
    "    query_data.to_csv('text/query.txt')\n",
    "    \n",
    "# generate_100_queires()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the transcript with all the 100 English sentences in it\n",
    "# stored in 'speech/transcript.txt'.\n",
    "def generate_transcript():\n",
    "    query_data = pd.read_csv('text/query.txt')\n",
    "    file = open('speech/transcript.txt', 'w')\n",
    "    for english in query_data['english']:\n",
    "        file.write(english + '\\n')\n",
    "    print('Use the transcript to generate audio files!')\n",
    "        \n",
    "# generate_transcript()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
